#!/usr/bin/env python3
# debug_embeddings.py

import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from scripts.filemaker_extractor import FileMakerExtractor
from sentence_transformers import SentenceTransformer
import numpy as np
import json
import requests


def test_embeddings():
    # Connexion
    extractor = FileMakerExtractor()
    if not extractor.login():
        print("âŒ Impossible de se connecter Ã  FileMaker")
        return

    # ModÃ¨le
    print("ğŸ¤– Chargement du modÃ¨le...")
    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

    # Question
    question = "prix d une part pour cristal life en 2021"
    question_embedding = model.encode([question])

    print(f"ğŸ” Recherche: {question}\n")

    try:
        # âœ… MÃ‰THODE 1: RÃ©cupÃ©rer TOUS les chunks puis filtrer
        url = f"{extractor.server}/fmi/data/v1/databases/{extractor.database}/layouts/Chunks/records"
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {extractor.token}'
        }

        # RÃ©cupÃ©rer les premiers chunks
        params = {
            '_limit': 100  # Limite pour le test
        }

        response = requests.get(url, headers=headers, params=params, verify=False)

        if response.status_code == 200:
            data = response.json()
            all_chunks = data['response']['data']

            print(f"ğŸ“„ Total chunks rÃ©cupÃ©rÃ©s: {len(all_chunks)}")

            # Filtrer ceux qui contiennent "cristal"
            cristal_chunks = []
            for chunk_record in all_chunks:
                chunk_data = chunk_record['fieldData']
                text = chunk_data.get('Text', '')  # â† Attention: "Text" avec majuscule

                if 'cristal' in text.lower():
                    cristal_chunks.append(chunk_data)

            print(f"ğŸ¯ {len(cristal_chunks)} chunks avec 'cristal' trouvÃ©s\n")

            # Analyser chaque chunk cristal
            for i, chunk_data in enumerate(cristal_chunks[:5]):  # Limite Ã  5

                print(f"--- CHUNK CRISTAL {i + 1} ---")
                print(f"ID Document: {chunk_data.get('idDocument', 'N/A')}")
                print(f"Texte: {chunk_data.get('Text', '')[:300]}...")

                # RÃ©cupÃ©rer l'embedding depuis EmbeddingJson
                embedding_str = chunk_data.get('EmbeddingJson', '')

                if embedding_str and embedding_str.strip():
                    try:
                        # Convertir l'embedding JSON en array
                        embedding = json.loads(embedding_str)

                        # Calculer la similaritÃ©
                        similarity = np.dot(question_embedding[0], np.array(embedding))

                        print(f"âœ… SimilaritÃ©: {similarity:.4f}")

                        # Mettre en Ã©vidence si trÃ¨s similaire
                        if similarity > 0.3:
                            print("ğŸ”¥ TRÃˆS SIMILAIRE Ã€ VOTRE QUESTION !")
                        elif similarity > 0.2:
                            print("ğŸŸ¡ Assez similaire")
                        else:
                            print("ğŸ”µ Peu similaire")

                    except json.JSONDecodeError as e:
                        print(f"âŒ Embedding JSON invalide: {e}")
                    except Exception as e:
                        print(f"âŒ Erreur calcul similaritÃ©: {e}")
                else:
                    print("âŒ Pas d'embedding trouvÃ© pour ce chunk")

                print("-" * 80)

        else:
            print(f"âŒ Erreur rÃ©cupÃ©ration chunks: {response.status_code}")
            print(response.text)

    except Exception as e:
        print(f"âŒ Erreur gÃ©nÃ©rale: {e}")
        import traceback
        traceback.print_exc()

    finally:
        extractor.logout()


if __name__ == '__main__':
    test_embeddings()
